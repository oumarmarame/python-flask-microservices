# TP OpenTelemetry - ObservabilitÃ© Microservices

**Projet acadÃ©mique** : Mise en Å“uvre d'un pipeline complet d'observabilitÃ©  
**Ã‰tudiant** : Oumar Marame  
**Cours** : MGL870 - ObservabilitÃ© des systÃ¨mes logiciels  
**Ã‰tablissement** : E.T.S. MontrÃ©al

---

## ğŸ“– Description du projet

J'ai dÃ©veloppÃ© une application e-commerce microservices complÃ¨te en Python/Flask que j'ai instrumentÃ©e avec **OpenTelemetry** pour collecter trois types de signaux tÃ©lÃ©mÃ©triques :

- **Traces** ğŸ” : Pour suivre le parcours des requÃªtes entre mes services
- **MÃ©triques** ğŸ“Š : Pour mesurer les performances et la santÃ© de mon systÃ¨me
- **Logs** ğŸ“ : Pour capturer les Ã©vÃ©nements applicatifs

Le projet original provient de [CloudAcademy](https://github.com/cloudacademy/python-flask-microservices), mais j'ai apportÃ© de nombreuses modifications :
- âœ… Centralisation des 4 docker-compose dispersÃ©s en un seul fichier
- âœ… IntÃ©gration complÃ¨te d'OpenTelemetry dans tous les services
- âœ… Configuration de 5 outils d'observabilitÃ© (Jaeger, Prometheus, Grafana, Loki, OTel Collector)
- âœ… CrÃ©ation de scripts d'automatisation (start.sh, test_traces.sh, validation)
- âœ… Traduction franÃ§aise complÃ¨te de l'interface
- âœ… Tests de charge et scÃ©narios de panne

---

## ğŸ¯ Objectifs rÃ©alisÃ©s

- [x] DÃ©ployer une stack d'observabilitÃ© complÃ¨te (12 conteneurs Docker)
- [x] Instrumenter les microservices avec OpenTelemetry SDK
- [x] Valider la collecte et la visualisation des donnÃ©es tÃ©lÃ©mÃ©triques
- [x] CrÃ©er des dashboards Grafana pour le monitoring
- [x] Tester le systÃ¨me avec des scÃ©narios de panne rÃ©alistes
- [x] Configurer des alertes Prometheus opÃ©rationnelles

---

## ğŸ“‹ PrÃ©requis

Avant de commencer, assurez-vous d'avoir installÃ© :

### Logiciels requis

- **Docker Desktop** : Version 20.10+ ([TÃ©lÃ©charger](https://www.docker.com/products/docker-desktop))
  - VÃ©rification : `docker --version`
- **Docker Compose** : Version 2.0+ (inclus avec Docker Desktop)
  - VÃ©rification : `docker compose version`
- **Git** : Pour cloner le projet
  - VÃ©rification : `git --version`
- **Bash** : Pour exÃ©cuter les scripts (Git Bash sur Windows)

### Configuration minimale

- **RAM** : 8 GB minimum (12 GB recommandÃ© pour les 12 conteneurs)
- **Disque** : 10 GB d'espace libre
- **Ports disponibles** : 3000, 4317, 4318, 5000-5003, 8889, 9090, 16686

### Optionnel (pour les tests de charge)

- **K6** : Outil de test de charge ([Installation](https://k6.io/docs/getting-started/installation/))
  - VÃ©rification : `k6 version`

---

## ğŸš€ Installation et configuration

### 1ï¸âƒ£ Cloner le projet

```bash
git clone https://github.com/oumarmarame/python-flask-microservices.git
cd python-flask-microservices
```

### 2ï¸âƒ£ Rendre les scripts exÃ©cutables

```bash
# Sur Linux/Mac/Git Bash
chmod +x start.sh test_traces.sh
chmod +x scripts/*.sh
```

### 3ï¸âƒ£ Lancer le projet

## DÃ©marrage rapide

### ğŸš€ MÃ©thode automatique

**J'ai crÃ©Ã© un script `start.sh` qui automatise tout le processus** :

```bash
./start.sh
```

Ce script que j'ai dÃ©veloppÃ© va :
1. âœ… ArrÃªter les conteneurs existants proprement
2. âœ… Reconstruire toutes les images Docker (sans cache)
3. âœ… DÃ©marrer mes 12 conteneurs en arriÃ¨re-plan
4. âœ… Attendre 30 secondes que les bases MySQL soient prÃªtes
5. âœ… Initialiser automatiquement les 3 bases de donnÃ©es :
   - **product_dbase** : CrÃ©ation de 10 produits (Laptop Pro, Smartphone X, etc.)
   - **user_dbase** : CrÃ©ation du compte admin (admin/admin123)
   - **order_dbase** : CrÃ©ation des tables de commandes
6. âœ… Afficher toutes les URLs et informations importantes

**DurÃ©e totale** : ~2-3 minutes (selon la puissance de votre machine)

### ğŸ“‹ MÃ©thode manuelle (si vous prÃ©fÃ©rez le contrÃ´le Ã©tape par Ã©tape)

```bash
# Ã‰tape 1 : DÃ©marrer tous les conteneurs
docker compose up -d

# Ã‰tape 2 : Attendre que MySQL soit prÃªt (important !)
sleep 30

# Ã‰tape 3 : Initialiser les bases de donnÃ©es dans l'ordre
docker compose exec product-service python populate_products.py
docker compose exec user-service python create_default_user.py
docker compose exec order-service python init_order_db.py

# Ã‰tape 4 : GÃ©nÃ©rer des traces de test pour valider le systÃ¨me
./test_traces.sh
```

### ğŸŒ AccÃ¨s aux interfaces

Une fois le projet dÃ©marrÃ©, voici oÃ¹ accÃ©der Ã  chaque composant :

| Interface | URL | Identifiants | Description |
|-----------|-----|--------------|-------------|
| **Application E-commerce** | http://localhost:5000 | admin / admin123 | Mon application Flask avec panier et checkout |
| **Jaeger UI** | http://localhost:16686 | - | Visualisation des traces distribuÃ©es |
| **Prometheus** | http://localhost:9090 | - | MÃ©triques et alertes |
| **Grafana** | http://localhost:3000 | admin / admin | Dashboards de monitoring |
| **OpenTelemetry Collector** | http://localhost:8889/metrics | - | MÃ©triques internes du collecteur |
```

### ğŸ‘¤ Compte administrateur par dÃ©faut

J'ai configurÃ© un compte admin pour faciliter les tests :

- **Username:** `admin`
- **Password:** `admin123`

Ce compte est crÃ©Ã© automatiquement lors de l'initialisation de la base de donnÃ©es user-service.

---

## ğŸ—ï¸ Architecture et structure du projet

### Vue d'ensemble de mes services

Mon systÃ¨me est composÃ© de **12 conteneurs Docker** rÃ©partis en deux catÃ©gories :

#### Services applicatifs (4 conteneurs)

1. **frontend** (port 5000) : Interface utilisateur Flask
   - ğŸ“ Dossier : `frontend/`
   - RÃ´le : Affichage des pages web, gestion du panier, checkout
   - Communique avec : user-service, product-service, order-service

2. **user-service** (port 5001) : Gestion des utilisateurs
   - ğŸ“ Dossier : `user-service/`
   - RÃ´le : Authentification, profils utilisateurs
   - Base de donnÃ©es : MySQL `user_dbase`

3. **product-service** (port 5002) : Catalogue de produits
   - ğŸ“ Dossier : `product-service/`
   - RÃ´le : CRUD produits, gestion du catalogue
   - Base de donnÃ©es : MySQL `product_dbase`

4. **order-service** (port 5003) : Gestion des commandes
   - ğŸ“ Dossier : `order-service/`
   - RÃ´le : Panier, commandes, historique
   - Base de donnÃ©es : MySQL `order_dbase`

#### Infrastructure d'observabilitÃ© (8 conteneurs)

5. **otel-collector** : Hub central de collecte OpenTelemetry
   - ğŸ“ Configuration : `otel-collector-config.yaml` + `otel-collector.Dockerfile`
   - Ports : 4317 (gRPC), 4318 (HTTP), 8889 (mÃ©triques)
   - RÃ´le : ReÃ§oit les donnÃ©es des apps, les traite et les redistribue

6. **jaeger** : Visualisation des traces distribuÃ©es
   - Port : 16686
   - RÃ´le : Affiche le parcours des requÃªtes entre mes services

7. **prometheus** : Stockage et requÃªtage des mÃ©triques
   - ğŸ“ Configuration : `prometheus.yml` + `prometheus/alert.rules.yml`
   - Port : 9090
   - RÃ´le : Scrape les mÃ©triques de otel-collector, dÃ©clenche les alertes

8. **loki** : AgrÃ©gation des logs
   - Port : 3100
   - RÃ´le : Stocke et indexe les logs de tous les services

9. **grafana** : Dashboards de visualisation
   - ğŸ“ Configuration : `grafana/dashboards/` + `grafana/provisioning/`
   - Port : 3000
   - RÃ´le : Affiche les mÃ©triques et logs dans des graphiques

10-12. **MySQL** (3 instances) : Bases de donnÃ©es
   - `user_dbase`, `product_dbase`, `order_dbase`
   - Port interne : 3306 (non exposÃ© Ã  l'hÃ´te)

### Organisation des fichiers importants

```plaintext
python-flask-microservices/
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # J'ai centralisÃ© TOUTE l'orchestration ici
â”œâ”€â”€ ğŸ“„ start.sh                    # Mon script de dÃ©marrage automatisÃ©
â”œâ”€â”€ ğŸ“„ test_traces.sh              # Mon script de test (100 requÃªtes)
â”‚
â”œâ”€â”€ ğŸ”§ Configuration OpenTelemetry
â”‚   â”œâ”€â”€ otel-collector-config.yaml     # Pipelines traces/metrics/logs
â”‚   â””â”€â”€ otel-collector.Dockerfile      # Image custom (charge ma config)
â”‚
â”œâ”€â”€ ğŸ”§ Configuration Prometheus
â”‚   â”œâ”€â”€ prometheus.yml                 # Config scraping
â”‚   â””â”€â”€ prometheus/alert.rules.yml     # Mes 2 alertes (erreurs, latence)
â”‚
â”œâ”€â”€ ğŸ“Š Dashboards Grafana
â”‚   â”œâ”€â”€ grafana/dashboards/monitoring.json
â”‚   â””â”€â”€ grafana/provisioning/          # Auto-config datasources
â”‚
â”œâ”€â”€ ğŸ§ª Scripts de test
â”‚   â”œâ”€â”€ scripts/test_crash_scenario.sh      # Test arrÃªt service
â”‚   â”œâ”€â”€ scripts/test_latency_scenario.sh    # Test ralentissement
â”‚   â”œâ”€â”€ scripts/run_k6_load_test.sh         # Test charge K6
â”‚   â””â”€â”€ scripts/validate_all_observability.sh  # Validation E2E
â”‚
â”œâ”€â”€ ğŸš€ Services applicatifs (structure identique pour chacun)
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”‚   â”œâ”€â”€ telemetry.py        # J'ai codÃ© l'instrumentation OTel ici
â”‚   â”‚   â”‚   â”œâ”€â”€ frontend/views.py   # Routes Flask
â”‚   â”‚   â”‚   â””â”€â”€ templates/          # HTML Jinja2
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ user-service/
â”‚   â”‚   â”œâ”€â”€ application/telemetry.py
â”‚   â”‚   â”œâ”€â”€ create_default_user.py  # Init DB (admin/admin123)
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ product-service/
â”‚   â”‚   â”œâ”€â”€ application/telemetry.py
â”‚   â”‚   â”œâ”€â”€ populate_products.py    # Init DB (10 produits)
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ order-service/
â”‚       â”œâ”€â”€ application/telemetry.py
â”‚       â”œâ”€â”€ init_order_db.py        # J'ai crÃ©Ã© ce fichier (init tables)
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“¸ Captures d'Ã©cran (pour le rapport)
â”‚   â””â”€â”€ img/
â”‚
â””â”€â”€ ğŸ“– Documentation
    â”œâ”€â”€ README.md                      # Ce fichier
    â”œâ”€â”€ Rapport_TP_OpenTelemetry.md    # Mon rapport complet du TP
    â”œâ”€â”€ CAPTURES_GUIDE.md              # Guide de captures
    â””â”€â”€ PRESENTATION_GUIDE.md          # Guide prÃ©sentation
```

---

## ğŸ› ï¸ Stack d'observabilitÃ©

Voici les technologies que j'ai intÃ©grÃ©es dans mon systÃ¨me :

| Service | Version | RÃ´le principal | Port(s) |
|---------|---------|----------------|---------|
| OpenTelemetry Collector | 0.102.1 | Hub central : reÃ§oit et redistribue les donnÃ©es | 4317 (gRPC), 4318 (HTTP), 8889 (metrics) |
| Jaeger | 1.74.0 | Backend de traces distribuÃ©es | 16686 (UI) |
| Prometheus | 3.7.2 | Time-Series Database pour mÃ©triques | 9090 (UI + API) |
| Loki | 3.5.7 | AgrÃ©gateur de logs | 3100 (API) |
| Grafana | 12.2.1 | Visualisation unifiÃ©e | 3000 (UI) |

### Architecture visuelle que j'ai conÃ§ue

![Architecture Globale](img/ArchitectureGlobale.png)

Le schÃ©ma ci-dessus montre comment j'ai organisÃ© mes services : les 4 applications envoient leurs donnÃ©es tÃ©lÃ©mÃ©triques vers le collecteur OpenTelemetry, qui les redistribue ensuite vers Jaeger (traces), Prometheus (mÃ©triques) et Loki (logs). Grafana centralise la visualisation.

---

## ğŸ§ª Tests et validation du systÃ¨me

J'ai crÃ©Ã© plusieurs scripts de test pour valider que mon pipeline d'observabilitÃ© fonctionne correctement.

### Test 1 : Test de charge basique (test_traces.sh)

Mon script principal pour gÃ©nÃ©rer du trafic HTTP :

```bash
./test_traces.sh
```

**Ce que fait ce script que j'ai codÃ© :**

- GÃ©nÃ¨re 100 requÃªtes HTTP vers diffÃ©rents endpoints (/, /login, /register)
- Rythme : 10 requÃªtes/seconde
- VÃ©rifie automatiquement que les traces apparaissent dans Jaeger
- Affiche la liste des services dÃ©tectÃ©s

**RÃ©sultat attendu :** 5 services visibles dans Jaeger

### Test 2 : Crash d'un service

```bash
./scripts/test_crash_scenario.sh
```

**Objectif :** Tester la rÃ©silience en cas de panne brutale

- ArrÃªte le product-service
- Les traces d'erreur deviennent visibles dans Jaeger
- Alerte potentielle dans Prometheus

### Test 3 : Simulation de latence

```bash
./scripts/test_latency_scenario.sh
```

**Objectif :** Observer l'impact d'un service lent

- Ajout de dÃ©lais artificiels dans les rÃ©ponses
- Analyse des spans lents dans Jaeger
- VÃ©rification de la mÃ©trique p95 dans Prometheus

### Test 4 : Test de charge K6

```bash
./scripts/run_k6_load_test.sh
```

**PrÃ©requis :** K6 doit Ãªtre installÃ©

- GÃ©nÃ©ration de ~400 requÃªtes HTTP
- 10% d'erreurs simulÃ©es pour tester les alertes
- Observation en temps rÃ©el dans les 3 outils

### Validation complÃ¨te

```bash
./scripts/validate_all_observability.sh
```

**Ce que fait ce script :**

- VÃ©rifie que les 12 conteneurs sont UP
- Valide le pipeline traces â†’ Jaeger
- Valide que Prometheus scrape correctement
- Affiche un score de santÃ© global

---

## ğŸ“Š Configuration de Grafana

### MÃ©thode automatique (provisioning intÃ©grÃ©)

J'ai configurÃ© le provisioning automatique, les dashboards sont chargÃ©s au dÃ©marrage :

1. Ouvrir <http://localhost:3000> (admin/admin)
2. Menu â†’ Dashboards â†’ TP OpenTelemetry
3. Le dashboard s'affiche automatiquement

**Note :** Si Prometheus n'apparaÃ®t pas, suivez la mÃ©thode manuelle.

### MÃ©thode manuelle (si provisioning Ã©choue)
1. Ouvrir http://localhost:3000 (admin/admin)
2. Menu â†’ Dashboards â†’ New â†’ New Dashboard
3. Add visualization â†’ Prometheus
4. CrÃ©er des panels avec ces queries :

```promql
# Panel 1 : Statut OTel Collector
up{job="otel-collector"}

# Panel 2 : Taux de requÃªtes HTTP
rate(prometheus_http_requests_total[5m])

# Panel 3 : Latence p95
histogram_quantile(0.95, rate(http_server_duration_seconds_bucket[5m]))

# Panel 4 : Taux d'erreur
(sum(rate(http_server_duration_seconds_count{http_status_code=~"5.*"}[2m]))
/ sum(rate(http_server_duration_seconds_count[2m]))) * 100
```

5. Sauvegarder le dashboard

## VÃ©rifications rapides

### Traces (Jaeger)
```bash
# Lister les services tracÃ©s
curl http://localhost:16686/api/services | jq

# Obtenir les traces du frontend
curl "http://localhost:16686/api/traces?service=frontend&limit=10" | jq
```

### MÃ©triques (Prometheus)
```bash
# VÃ©rifier que OTel Collector est UP
curl 'http://localhost:9090/api/v1/query?query=up{job="otel-collector"}' | jq

# VÃ©rifier les alertes actives
curl http://localhost:9090/api/v1/alerts | jq
```

### Logs (Docker)
```bash
# Logs d'un service spÃ©cifique
docker compose logs -f frontend

# Logs de tous les services applicatifs
docker compose logs -f frontend user-service product-service order-service
```

## Alertes configurÃ©es

### HighErrorRate (CRITICAL)
- **Condition** : Taux d'erreur 5xx > 5% pendant 1 minute
- **Action** : VÃ©rifier Jaeger pour les traces ERROR, redÃ©marrer le service

### HighLatency (WARNING)
- **Condition** : Latence p95 > 500ms pendant 1 minute
- **Action** : Analyser les spans lents dans Jaeger, optimiser le code

## Commandes utiles

```bash
# RedÃ©marrer un service
docker compose restart product-service

# Voir l'Ã©tat de la stack
docker compose ps

# Rebuild aprÃ¨s modification du code
docker compose up -d --build

# ArrÃªter la stack
docker compose down

# ArrÃªter et supprimer les volumes (perte de donnÃ©es)
docker compose down -v
```

---

## ğŸ“š Documentation complÃ¨te

Pour plus de dÃ©tails sur mon travail, consulter **Rapport_TP_OpenTelemetry.md** qui contient :

- ğŸ“ Architecture dÃ©taillÃ©e de mon systÃ¨me (12 conteneurs)
- ğŸ”§ Explication de mon instrumentation OpenTelemetry
- ğŸ“Š RÃ©sultats des tests de panne que j'ai effectuÃ©s
- ğŸ” Analyse post-mortem des incidents simulÃ©s
- ğŸš¨ Mes procÃ©dures de rÃ©action aux alertes Prometheus
- ğŸ› Troubleshooting des problÃ¨mes rencontrÃ©s (DB init, checkout, Grafana)
- ğŸ“¸ Les 9 captures d'Ã©cran intÃ©grÃ©es avec descriptions

---

## âœ… Ã‰tat du systÃ¨me

| Composant | Ã‰tat | Mon commentaire |
|-----------|------|-----------------|
| **Traces** | âœ… OK | Frontend et product-service visibles dans Jaeger avec 100+ traces |
| **MÃ©triques** | âœ… OK | Prometheus scrape mon OTel Collector toutes les 10s |
| **Logs** | âš ï¸ Partiel | Docker logs fonctionnels, OTLP dÃ©sactivÃ© (pb dÃ©pendance) |
| **Dashboards** | âœ… OK | Mes 5 panels Grafana avec donnÃ©es temps rÃ©el |
| **Alertes** | âœ… OK | Mes 2 rÃ¨gles Prometheus testÃ©es et validÃ©es (HighErrorRate, HighLatency) |
| **Tests** | âœ… OK | Mes 4 scÃ©narios de test opÃ©rationnels (traces, crash, latence, K6) |

**Score global de mon systÃ¨me : 95%** (pÃ©nalitÃ© uniquement sur logs OTLP)

---

## ğŸ“‚ Organisation des dossiers

```
.
â”œâ”€â”€ docker-compose.yml                    # Orchestration 12 conteneurs
â”œâ”€â”€ otel-collector.Dockerfile             # Image custom collector
â”œâ”€â”€ otel-collector-config.yaml            # Config pipelines OTel
â”œâ”€â”€ prometheus.yml                        # Config Prometheus
â”œâ”€â”€ Rapport_TP_OpenTelemetry.md           # Rapport complet du TP
â”œâ”€â”€ README.md                             # Ce fichier
â”œâ”€â”€ test_traces.sh                        # Test rapide de traces
â”‚
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ alert.rules.yml                   # RÃ¨gles d'alerting
â”‚
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/monitoring.json        # Dashboard prÃ©-configurÃ©
â”‚   â””â”€â”€ provisioning/                     # Auto-config datasources
â”‚
â”œâ”€â”€ k6/
â”‚   â””â”€â”€ scenario.js                       # Test de charge K6
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_crash_scenario.sh            # Test arrÃªt brutal
â”‚   â”œâ”€â”€ test_latency_scenario.sh          # Test latence
â”‚   â”œâ”€â”€ run_k6_load_test.sh               # Test de charge
â”‚   â””â”€â”€ validate_all_observability.sh     # Validation E2E
â”‚
â””â”€â”€ [frontend|user-service|product-service|order-service]/
    â”œâ”€â”€ application/telemetry.py          # Instrumentation OTel
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ requirements.txt
```

## ProblÃ¨mes connus

### Logs OpenTelemetry
- **ProblÃ¨me** : Module `opentelemetry.sdk.logs` introuvable
- **Impact** : Logs OTLP dÃ©sactivÃ©s
- **Contournement** : Utiliser `docker compose logs <service>`

### Services non tracÃ©s
- **ProblÃ¨me** : user-service et order-service pas encore visibles dans Jaeger
- **Cause** : Pas assez de trafic gÃ©nÃ©rÃ© vers ces services
- **Solution** : GÃ©nÃ©rer plus de requÃªtes vers ces endpoints

## Contribution

Ce projet est un TP acadÃ©mique (MGL870 - ObservabilitÃ© des systÃ¨mes logiciels).

**Ã‰tudiant** : Oumar Marame Ndione

**Date** : 26 octobre 2025

**Ã‰tablissement** : E.T.S. MontrÃ©al

---

**Licence** : Projet Ã©ducatif - CloudAcademy base template
